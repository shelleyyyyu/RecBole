# general
gpu_id: 0
use_gpu: True
seed: 2020
state: INFO
reproducibility: True
data_path: 'dataset/'
checkpoint_dir: 'saved'
show_progress: True
save_dataset: False
save_dataloaders: False

# training settings
epochs: 1000
train_batch_size: 512
learner: adam
learning_rate: 0.001
neg_sampling:
  uniform: 10
eval_step: 1
stopping_step: 100
clip_grad_norm:  {'max_norm': 5, 'norm_type': 2}
weight_decay: 0.0

# evaluation settings
eval_args: 
  split: {'RS':[0.9,0.05,0.05]}
  group_by: none
  order: RO
  mode: full
repeatable: False
metrics: ["Recall","Hit","Precision"]
topk: [1]
valid_metric: Hit@1
valid_metric_bigger: True
eval_batch_size: 512
loss_decimal_place: 4
metric_decimal_place: 4

# Sample

# Atomic File Format
field_separator: "\t"
seq_separator: " "

# Common Features
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
TIME_FIELD: timestamp
seq_len: ~

# Label for Point-wise DataLoader
LABEL_FIELD: label
threshold: {'rating':1}

# NegSample Prefix for Pair-wise DataLoader
NEG_PREFIX: neg_

# Selectively Loading
load_col:
    inter: ['user_id', 'item_id', 'rating']
    # the others
unload_col: ~
unused_col: ~
additional_feat_suffix: ~

# Filtering
rm_dup_inter: ~
val_interval: ~
filter_inter_by_user_or_item: True
user_inter_num_interval: "[0,inf)"
item_inter_num_interval: "[0,inf)"

# Preprocessing
alias_of_user_id: ~
alias_of_item_id: ~
alias_of_entity_id: ~
alias_of_relation_id: ~
preload_weight: ~
normalize_field: ~
normalize_all: ~

# Sequential Model Needed
ITEM_LIST_LENGTH_FIELD: item_length
LIST_SUFFIX: _list
MAX_ITEM_LIST_LENGTH: 50
POSITION_FIELD: position_id

# Knowledge-based Model Needed
HEAD_ENTITY_ID_FIELD: head_id
TAIL_ENTITY_ID_FIELD: tail_id
RELATION_ID_FIELD: relation_id
ENTITY_ID_FIELD: entity_id

# Benchmark .inter
benchmark_filename: ~
